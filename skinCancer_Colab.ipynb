{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoc769JEkaMx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJMeRz7subB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7024b789-a153-4075-bfb6-a4b84642374e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCTzwzQ_k1Sb"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/drive/MyDrive/train_skinCancer'\n",
        "test_dir = '/content/drive/MyDrive/test_skinCancer'\n",
        "train_benign_dr = '/content/drive/MyDrive/train_skinCancer/begnin'\n",
        "train_malignant_dr = '/content/drive/MyDrive/train_skinCancer/malignent'\n",
        "test_benign_dr = '/content/drive/MyDrive/test_skinCancer/begnin'\n",
        "test_malignant_dr = '/content/drive/MyDrive/test_skinCancer/malignent'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhR337dnmBuy",
        "outputId": "64b9c86e-e036-4031-858e-d702c23be654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 500 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_image_generator = ImageDataGenerator(rescale = 1./255)\n",
        "test_image_generator = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size = 128,\n",
        "                                                           directory = train_dir,\n",
        "                                                           shuffle = True,\n",
        "                                                           target_size = (224, 224),\n",
        "                                                           class_mode = 'binary')\n",
        "\n",
        "test_data_gen = test_image_generator.flow_from_directory(batch_size = 128,\n",
        "                                                         directory = test_dir,\n",
        "                                                         shuffle = True,\n",
        "                                                         target_size = (224, 224),\n",
        "                                                         class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMYOVpeRm2f2",
        "outputId": "0ff3fcda-b3bd-433a-ca48-fbf198f4d206"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_data_gen.image_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2wFFzyAnUMS"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D(pool_size = (2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Szx4mgS5n-Td"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b-qWMI4n8Hg",
        "outputId": "5b04cef9-d411-41dd-acc2-a84123e76834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 111, 111, 16)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 197136)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1971370   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                352       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,974,347\n",
            "Trainable params: 1,974,347\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhzDYnY1oJfl"
      },
      "outputs": [],
      "source": [
        "total_train_size = len(os.listdir(train_benign_dr)) + len(os.listdir(train_malignant_dr))\n",
        "total_test_size = len(os.listdir(test_benign_dr)) + len(os.listdir(test_malignant_dr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke18c2Qeoix8",
        "outputId": "0cc83b36-63f2-4672-d84e-c3481fa8e8bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3/3 [==============================] - 16s 5s/step - loss: 5.2453 - accuracy: 0.4866 - val_loss: 1.3609 - val_accuracy: 0.5312\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 14s 5s/step - loss: 1.0437 - accuracy: 0.5081 - val_loss: 0.6870 - val_accuracy: 0.5156\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 14s 5s/step - loss: 0.7285 - accuracy: 0.4704 - val_loss: 0.7282 - val_accuracy: 0.4844\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.6818 - accuracy: 0.5941 - val_loss: 0.7891 - val_accuracy: 0.4609\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 14s 5s/step - loss: 0.6925 - accuracy: 0.5188 - val_loss: 0.7158 - val_accuracy: 0.5547\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 15s 6s/step - loss: 0.5862 - accuracy: 0.6989 - val_loss: 0.6606 - val_accuracy: 0.5781\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.5293 - accuracy: 0.7796 - val_loss: 0.6866 - val_accuracy: 0.6797\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.5089 - accuracy: 0.7392 - val_loss: 0.6745 - val_accuracy: 0.6562\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 15s 5s/step - loss: 0.4970 - accuracy: 0.7769 - val_loss: 0.6336 - val_accuracy: 0.6953\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 14s 5s/step - loss: 0.4543 - accuracy: 0.7903 - val_loss: 0.6046 - val_accuracy: 0.7109\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 11s 4s/step - loss: 0.4595 - accuracy: 0.7796 - val_loss: 0.6721 - val_accuracy: 0.6484\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 14s 6s/step - loss: 0.4497 - accuracy: 0.7849 - val_loss: 0.7361 - val_accuracy: 0.6562\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 14s 5s/step - loss: 0.4230 - accuracy: 0.8091 - val_loss: 0.6554 - val_accuracy: 0.6328\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 12s 5s/step - loss: 0.3868 - accuracy: 0.8360 - val_loss: 0.7569 - val_accuracy: 0.6719\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 22s 8s/step - loss: 0.4091 - accuracy: 0.8099 - val_loss: 0.6640 - val_accuracy: 0.6484\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 12s 4s/step - loss: 0.3474 - accuracy: 0.8542 - val_loss: 0.6367 - val_accuracy: 0.7109\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.3775 - accuracy: 0.8255 - val_loss: 0.6176 - val_accuracy: 0.6719\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 14s 5s/step - loss: 0.3395 - accuracy: 0.8548 - val_loss: 0.7386 - val_accuracy: 0.6562\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 15s 6s/step - loss: 0.3437 - accuracy: 0.8414 - val_loss: 0.5887 - val_accuracy: 0.7031\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 15s 6s/step - loss: 0.3297 - accuracy: 0.8522 - val_loss: 0.6320 - val_accuracy: 0.7031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d1e47600700>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model.fit(train_data_gen,\n",
        "          batch_size = 128,\n",
        "          epochs = 20,\n",
        "          steps_per_epoch = total_train_size // 128,\n",
        "          validation_data = test_data_gen,\n",
        "          validation_steps = total_test_size // 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us_LEJbsz2Zf"
      },
      "outputs": [],
      "source": [
        "def result(predictions):\n",
        "  if predictions > 0.5:\n",
        "    print(\"Malignant\")\n",
        "  else:\n",
        "    print(\"benign\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RW9uQwMxfju"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "image_path = '/content/drive/MyDrive/test_skinCancer/begnin/melanoma_9614.jpg'\n",
        "image = Image.open(image_path)\n",
        "image = image.resize((224, 224))\n",
        "image = np.array(image) / 255.0\n",
        "\n",
        "image = image.reshape((1, 224, 224, 3))\n",
        "\n",
        "predictions = model.predict(image)\n",
        "print(predictions)\n",
        "result(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcGlT7mrxqQ1"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "image_path = '/content/drive/MyDrive/test_skinCancer/begnin/melanoma_9719.jpg'\n",
        "image = Image.open(image_path)\n",
        "image = image.resize((224, 224))\n",
        "image = np.array(image) / 255.0\n",
        "\n",
        "image = image.reshape((1, 224, 224, 3))\n",
        "\n",
        "predictions = model.predict(image)\n",
        "print(predictions)\n",
        "result(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDNITC1Mx2PK"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "image_path = '/content/drive/MyDrive/test_skinCancer/malignent/melanoma_10202.jpg'\n",
        "image = Image.open(image_path)\n",
        "image = image.resize((224, 224))\n",
        "image = np.array(image) / 255.0\n",
        "\n",
        "image = image.reshape((1, 224, 224, 3))\n",
        "\n",
        "predictions = model.predict(image)\n",
        "print(predictions)\n",
        "result(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuB8sg24yC0L"
      },
      "outputs": [],
      "source": [
        "tf.keras.models.save_model(model,'my_model.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_XrqCS1GCkf"
      },
      "outputs": [],
      "source": [
        "! pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-_OuZ3YGCpM"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import streamlit as st\n",
        "\n",
        "\n",
        "@st.cache(allow_output_mutation=True)\n",
        "def load_model():\n",
        "  model=tf.keras.models.load_model('/content/my_model.hdf5')\n",
        "  return model\n",
        "with st.spinner('Model is being loaded..'):\n",
        "  model=load_model()\n",
        "\n",
        "st.write(\"\"\"\n",
        "         # Skin cancer prediction\n",
        "         \"\"\"\n",
        "         )\n",
        "\n",
        "file = st.file_uploader(\"Please upload an brain scan file\", type=[\"jpg\", \"png\"])\n",
        "import cv2\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "def import_and_predict(image_data, model):\n",
        "\n",
        "        size = (224, 224)\n",
        "        image = ImageOps.fit(image_data, size, Image.ANTIALIAS)\n",
        "        image = np.asarray(image)\n",
        "        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        #img_resize = (cv2.resize(img, dsize=(75, 75),    interpolation=cv2.INTER_CUBIC))/255.\n",
        "\n",
        "        img_reshape = img[np.newaxis,...]\n",
        "\n",
        "        prediction = model.predict(img_reshape)\n",
        "\n",
        "        return prediction\n",
        "if file is None:\n",
        "    st.text(\"Please upload an image file\")\n",
        "else:\n",
        "    image = Image.open(file)\n",
        "    st.image(image, use_column_width=True)\n",
        "    predictions = import_and_predict(image, model)\n",
        "    score = tf.nn.softmax(predictions[0])\n",
        "    st.write(predictions)\n",
        "    st.write(score)\n",
        "    class_names = ['Malignent','bengin']\n",
        "    print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFAdG43sKquo"
      },
      "outputs": [],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er8wnBq6KqxD"
      },
      "outputs": [],
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zlp58oLLU3g"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.models.save_model(model,'my_model.hdf5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}